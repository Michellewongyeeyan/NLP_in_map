{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2906bfe",
   "metadata": {},
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8894c18-0e86-422e-81f8-410419b58d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Basis\n",
    "# %pip install --upgrade pip --quiet\n",
    "\n",
    "# # NLP\n",
    "# %pip install pandas --quiet\n",
    "# %pip install spacy --quiet\n",
    "# # 效率\n",
    "# # !python -m spacy download en_core_web_md\n",
    "# # !python -m spacy download en_core_web_sm\n",
    "# # 準確性 \n",
    "# !spacy download en_core_web_trf -q\n",
    "\n",
    "# # NLP 2\n",
    "# # !pip install nltk\n",
    "\n",
    "# # For Map\n",
    "# %pip install geopy --quiet\n",
    "\n",
    "# # other\n",
    "# %pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c80169",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76177328-63ac-4413-8a71-efea53de1e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ansoncar/Sync/My/MyProject/NLP_in_map/.venv/lib/python3.10/site-packages/thinc/shims/pytorch.py:253: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(filelike, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_trf\");\n",
    "from geopy.geocoders import Nominatim\n",
    "# import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06aedce",
   "metadata": {},
   "source": [
    "## exsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d3ffbe75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to hong kong\n",
      "[('Welcome', 'INTJ'), ('to', 'ADP'), ('hong', 'PROPN'), ('kong', 'PROPN')]\n",
      "hong kong GPE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "doc = nlp(\"Welcome to hong kong\")\n",
    "print(doc)\n",
    "print([(w.text, w.pos_) for w in doc])\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == 'GPE':  # GPE 表示地理政治实体\n",
    "        print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdba291",
   "metadata": {},
   "source": [
    "# 1. 預處理數據"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960a5818",
   "metadata": {},
   "source": [
    "## 根據 [ 章節號碼 ] 分出 十八章節，存放在 chapter list 之中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6ae26c56-b7bf-4198-808d-78c3233e1f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = []\n",
    "chapter_num = 0\n",
    "\n",
    "file_path = './data/JamesJoyce-Ulysses_Ans.txt'\n",
    "\n",
    "# open file\n",
    "# with open(file_path, \"r\", encoding='utf-8-sig') as file:\n",
    "with open(file_path, \"r\") as file:\n",
    "    # loop each line\n",
    "    for line in file:\n",
    "        # 分章節\n",
    "        if line.strip().startswith(f'[ { chapter_num+1} ]'):\n",
    "            chapter_num += 1\n",
    "            chapters.append('')\n",
    "            # 唔要章節號碼\n",
    "        else:\n",
    "            # save line\n",
    "            chapters[chapter_num-1] += line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56608b00",
   "metadata": {},
   "source": [
    "# 根據 \\n\\n，幫每一個章節 分每一句句子出泥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "03807a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters_v2 = []\n",
    "\n",
    "for chapter in chapters:\n",
    "   chapters_v2.append(chapter.split('\\n\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9f5d7f",
   "metadata": {},
   "source": [
    "# 根據 \\n，幫每一句句子嘅\\n 變成 空格，合返做一行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6e9de7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters_v3 = []\n",
    "# 每一個章節\n",
    "for chapter_num, chapter in enumerate(chapters_v2):\n",
    "    chapters_v3.append([])\n",
    "    # 每一個句子\n",
    "    for index, line  in enumerate(chapter):\n",
    "        # 換 \\n 同 去頭尾空格\n",
    "        text = str(line).replace('\\n', ' ').strip()\n",
    "        # 去除空白行\n",
    "        if (text != '' and text != ' '):\n",
    "            chapters_v3[chapter_num].append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a9a4bd",
   "metadata": {},
   "source": [
    "# 2. NLP Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4874b12",
   "metadata": {},
   "source": [
    "# check 每一句句子嘅地點"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "236df765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stately, plump Buck Mulligan came from the stairhead, bearing a bowl of lather on which a mirror and a razor lay crossed. A yellow dressinggown, ungirdled, was sustained gently behind him on the mild morning air. He held the bowl aloft and intoned:\n",
      "[('Stately', 'ADV'), (',', 'PUNCT'), ('plump', 'ADJ'), ('Buck', 'PROPN'), ('Mulligan', 'PROPN'), ('came', 'VERB'), ('from', 'ADP'), ('the', 'DET'), ('stairhead', 'NOUN'), (',', 'PUNCT'), ('bearing', 'VERB'), ('a', 'DET'), ('bowl', 'NOUN'), ('of', 'ADP'), ('lather', 'NOUN'), ('on', 'ADP'), ('which', 'PRON'), ('a', 'DET'), ('mirror', 'NOUN'), ('and', 'CCONJ'), ('a', 'DET'), ('razor', 'NOUN'), ('lay', 'VERB'), ('crossed', 'VERB'), ('.', 'PUNCT'), ('A', 'DET'), ('yellow', 'ADJ'), ('dressinggown', 'NOUN'), (',', 'PUNCT'), ('ungirdled', 'VERB'), (',', 'PUNCT'), ('was', 'AUX'), ('sustained', 'VERB'), ('gently', 'ADV'), ('behind', 'ADP'), ('him', 'PRON'), ('on', 'ADP'), ('the', 'DET'), ('mild', 'ADJ'), ('morning', 'NOUN'), ('air', 'NOUN'), ('.', 'PUNCT'), ('He', 'PRON'), ('held', 'VERB'), ('the', 'DET'), ('bowl', 'NOUN'), ('aloft', 'ADV'), ('and', 'CCONJ'), ('intoned', 'VERB'), (':', 'PUNCT')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Stately, plump \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Buck Mulligan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " came from the stairhead, bearing a bowl of lather on which a mirror and a razor lay crossed. A yellow dressinggown, ungirdled, was sustained gently behind him on the mild \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    morning\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       " air. He held the bowl aloft and intoned:</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for chapter in chapters_v3:\n",
    "#     for line in chapter:\n",
    "#         spacy.displacy.render(nlp(line),style=\"ent\")\n",
    "\n",
    "doc = nlp(chapters_v3[0][0])\n",
    "print(doc)\n",
    "print([(w.text, w.pos_) for w in doc])\n",
    "\n",
    "spacy.displacy.render(doc,style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1d2020",
   "metadata": {},
   "source": [
    "# 實做"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2a3d7901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpe_data = []\n",
    "# # 每一個章節\n",
    "# for chapter_num, chapter in enumerate(chapters_v3):\n",
    "#     gpe_data.append({})\n",
    "#     # 每一句句子\n",
    "#     for line_num, line in enumerate(chapter):\n",
    "#         text = nlp(line)\n",
    "#         for ent in text.ents:\n",
    "#             if ent.label_ == \"GPE\":  # GPE 表示地理政治实体\n",
    "#                 gpe_name = gpe_data[chapter_num].get(ent.text)\n",
    "#                 if not gpe_name:\n",
    "#                     gpe_data[chapter_num][ent.text] = 0\n",
    "#                 gpe_data[chapter_num][ent.text] += 1\n",
    "#     break\n",
    "# gpe_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0926ebf4",
   "metadata": {},
   "source": [
    "# 3. 揾地點 座標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d87d0883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40.7127281, -74.0060152)\n"
     ]
    }
   ],
   "source": [
    "geolocator = Nominatim(user_agent=\"damn boy\")\n",
    "location = geolocator.geocode(\"New York City\")\n",
    "\n",
    "if location:\n",
    "    print((location.latitude, location.longitude))\n",
    "else:\n",
    "    print(\"Location not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8902771",
   "metadata": {},
   "source": [
    "# 寫一個 function for loop 曬所有 chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5d0ec009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpe(chapter: list):\n",
    "    geolocator = Nominatim(user_agent=\"damn boy\")\n",
    "    ret = {}\n",
    "    # 每一句句子\n",
    "    for line_num, line in enumerate(chapter):\n",
    "        # 分析句子\n",
    "        text = nlp(line)\n",
    "        # 查看每一個字詞性\n",
    "        for ent in text.ents:\n",
    "            # GPE 表示地理政治实体，係就拎出泥\n",
    "            if ent.label_ == \"GPE\":\n",
    "                if not ret.get(ent.text):\n",
    "                    ret[ent.text] = {\"nominatim\": [], \"lines\": [], \"count\": 0, 'text':[]}\n",
    "                    query = f\"{ent.text}, Ireland\"\n",
    "                    location = geolocator.geocode(query)\n",
    "                    if location:\n",
    "                        ret[ent.text][\"nominatim\"] = [location.latitude, location.longitude]\n",
    "                    else:\n",
    "                        print(ent.text, \"Location not found\")\n",
    "\n",
    "                if line_num not in ret[ent.text][\"lines\"] and line not in ret[ent.text][\"text\"]:\n",
    "                    ret[ent.text][\"lines\"].append(line_num)\n",
    "                    ret[ent.text][\"text\"].append(line)\n",
    "                    ret[ent.text][\"count\"] += 1\n",
    "    return ret\n",
    "\n",
    "# output json file\n",
    "def toJson(data:dict, name:str):\n",
    "    json_output = json.dumps(data, indent=4, ensure_ascii=False)\n",
    "    output_dir = './dist/'\n",
    "\n",
    "    # 檢查目標目錄是否存在，不存在則創建\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    with open(f'{output_dir}{name}.json', 'w', encoding='utf-8' ) as f:\n",
    "        f.write(json_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eb1dd0",
   "metadata": {},
   "source": [
    "# 開始所有"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e9eecd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for chapter_num, chapter in enumerate(chapters_v3):\n",
    "#     print(f'RUN chapter {chapter_num+1}')\n",
    "#     data = get_gpe(chapter)\n",
    "#     toJson(data, f'chapter_{chapter_num+1}_gpe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd1e529",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3be4fe40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN chapter 1\n",
      "Dottyville Location not found\n"
     ]
    }
   ],
   "source": [
    "num = 1\n",
    "print(f'RUN chapter {num}')\n",
    "data = get_gpe(chapters_v3[num-1])\n",
    "toJson(data, f'chapter_{num}_gpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "25f16600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN chapter 2\n",
      "Mürzsteg Location not found\n"
     ]
    }
   ],
   "source": [
    "num = 2\n",
    "print(f'RUN chapter {num}')\n",
    "data = get_gpe(chapters_v3[num-1])\n",
    "toJson(data, f'chapter_{num}_gpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "38aa7701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN chapter 3\n",
      "Barcelona Location not found\n",
      "Romeville Location not found\n"
     ]
    }
   ],
   "source": [
    "num = 3\n",
    "print(f'RUN chapter {num}')\n",
    "data = get_gpe(chapters_v3[num-1])\n",
    "toJson(data, f'chapter_{num}_gpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "42a41203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN chapter 4\n",
      "Kinnereth Location not found\n",
      "Tiberias Location not found\n",
      "Sodom Location not found\n",
      "Gomorrah Location not found\n",
      "Edom Location not found\n"
     ]
    }
   ],
   "source": [
    "num = 4\n",
    "print(f'RUN chapter {num}')\n",
    "data = get_gpe(chapters_v3[num-1])\n",
    "toJson(data, f'chapter_{num}_gpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b8a879e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN chapter 5\n"
     ]
    }
   ],
   "source": [
    "num = 5\n",
    "print(f'RUN chapter {num}')\n",
    "data = get_gpe(chapters_v3[num-1])\n",
    "toJson(data, f'chapter_{num}_gpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "03ffaa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN chapter 6\n",
      "the Isle of Man Location not found\n",
      "Roundtown Location not found\n"
     ]
    }
   ],
   "source": [
    "num = 6\n",
    "print(f'RUN chapter {num}')\n",
    "data = get_gpe(chapters_v3[num-1])\n",
    "toJson(data, f'chapter_{num}_gpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3cacddd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN chapter 7\n",
      "Clonskea Location not found\n",
      "Manx Location not found\n",
      "Brixton Location not found\n",
      "SHINDY Location not found\n",
      "Habsburg Location not found\n",
      "Roundtown Location not found\n",
      "VIRGILIAN Location not found\n",
      "SOPHOMORE Location not found\n",
      "FLO WANGLES Location not found\n"
     ]
    }
   ],
   "source": [
    "num = 7\n",
    "print(f'RUN chapter {num}')\n",
    "data = get_gpe(chapters_v3[num-1])\n",
    "toJson(data, f'chapter_{num}_gpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f10dd355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN chapter 8\n",
      "Zion Location not found\n",
      "exc. Location not found\n",
      "Rathoath Location not found\n",
      "Kerwan Location not found\n",
      "the Red Bank Location not found\n",
      "Margate Location not found\n",
      "Levenston Location not found\n"
     ]
    }
   ],
   "source": [
    "num = 8\n",
    "print(f'RUN chapter {num}')\n",
    "data = get_gpe(chapters_v3[num-1])\n",
    "toJson(data, f'chapter_{num}_gpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2241efb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN chapter 9\n",
      "Mallarmé Location not found\n",
      "Pickwick Location not found\n",
      "Romeville Location not found\n",
      "Clamart Location not found\n",
      "Sheba Location not found\n",
      "Almany Location not found\n",
      "Ultonian Antrim Location not found\n",
      "Wittenberg Location not found\n",
      "Southwark Location not found\n",
      "Cymbeline Location not found\n"
     ]
    }
   ],
   "source": [
    "num = 9\n",
    "print(f'RUN chapter {num}')\n",
    "data = get_gpe(chapters_v3[num-1])\n",
    "toJson(data, f'chapter_{num}_gpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "464e56d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN chapter 10\n",
      "Fehrenbach Location not found\n",
      "Potterton Location not found\n",
      "palmam ferenti Location not found\n",
      "Llandudno Location not found\n",
      "Bridgwater Location not found\n"
     ]
    }
   ],
   "source": [
    "num = 10\n",
    "print(f'RUN chapter {num}')\n",
    "data = get_gpe(chapters_v3[num-1])\n",
    "toJson(data, f'chapter_{num}_gpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5517f7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN chapter 11\n",
      "Yessex Location not found\n",
      "Ternoon Location not found\n",
      "Dedalus Location not found\n",
      "Yashmak Location not found\n",
      "Persia Location not found\n"
     ]
    }
   ],
   "source": [
    "num = 11\n",
    "print(f'RUN chapter {num}')\n",
    "data = get_gpe(chapters_v3[num-1])\n",
    "toJson(data, f'chapter_{num}_gpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "241148a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN chapter 12\n",
      "Exeter Location not found\n",
      "Iffley Location not found\n",
      "Playwood Location not found\n",
      "Stoke Newington Location not found\n",
      "Chepstow Location not found\n",
      "the United Kingdom Location not found\n",
      "O’Dignam Location not found\n",
      "Pentonville Location not found\n",
      "Buncombe Location not found\n",
      "Heligoland Location not found\n",
      "Oakholme Regis Location not found\n",
      "Omaha Location not found\n",
      "Rio de Janeiro Location not found\n",
      "Tetuan Location not found\n",
      "Carrantuohill Location not found\n",
      "Clonmacnois Location not found\n",
      "Lough Neagh’s Location not found\n",
      "Castleconnel Location not found\n",
      "Kilballymacshonakill Location not found\n",
      "Abeakuta Location not found\n",
      "Cottonopolis Location not found\n",
      "the Congo Free State Location not found\n",
      "Viterbo Location not found\n"
     ]
    }
   ],
   "source": [
    "num = 12\n",
    "print(f'RUN chapter {num}')\n",
    "data = get_gpe(chapters_v3[num-1])\n",
    "toJson(data, f'chapter_{num}_gpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c43b3c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN chapter 13\n",
      "Borneo Location not found\n"
     ]
    }
   ],
   "source": [
    "num = 13\n",
    "print(f'RUN chapter {num}')\n",
    "data = get_gpe(chapters_v3[num-1])\n",
    "toJson(data, f'chapter_{num}_gpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "faaca6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN chapter 14\n",
      "Alba Longa Location not found\n",
      "Almany Location not found\n",
      "Madagascar Location not found\n",
      "Oxtail Location not found\n",
      "Horeb Location not found\n",
      "Pisgah Location not found\n",
      "the Horns of Hatten Location not found\n",
      "Tophet Location not found\n",
      "Cape Horn Location not found\n",
      "Bashan Location not found\n",
      "Lethe Location not found\n",
      "linseywoolsey Location not found\n",
      "Juda Location not found\n",
      "Chawley Location not found\n",
      "Au reservoir Location not found\n",
      "mossoo Location not found\n",
      "chokeechokee Location not found\n",
      "Bawdyhouse Location not found\n",
      "Vladivostok Location not found\n"
     ]
    }
   ],
   "source": [
    "num = 14\n",
    "print(f'RUN chapter {num}')\n",
    "data = get_gpe(chapters_v3[num-1])\n",
    "toJson(data, f'chapter_{num}_gpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5d8ae3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN chapter 15\n",
      "Zion Location not found\n",
      "Livermore Location not found\n",
      "Bloemfontein Location not found\n",
      "LONGHAND Location not found\n",
      "SHORTHAND Location not found\n",
      "Kinnereth Location not found\n",
      "the North Riding of Tipperary Location not found\n",
      "Bloomusalem Location not found\n",
      "the Nova Hibernia Location not found\n",
      "PAPAL NUNCIO Location not found\n",
      "Agendath Netaim Location not found\n",
      "Mizraim Location not found\n",
      "CITRON Location not found\n",
      "Istria Location not found\n",
      "Pflaap Location not found\n",
      "Nankeen Location not found\n",
      "Szombathely Location not found\n",
      "Candia Location not found\n",
      "Watercloset Location not found\n"
     ]
    }
   ],
   "source": [
    "num = 15\n",
    "print(f'RUN chapter {num}')\n",
    "data = get_gpe(chapters_v3[num-1])\n",
    "toJson(data, f'chapter_{num}_gpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fa9cad1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN chapter 16\n",
      "Stockholm Location not found\n",
      "Bridgwater Location not found\n",
      "Beni Location not found\n",
      "Bolivia Location not found\n",
      "Santiago Location not found\n",
      "Southampton Location not found\n",
      "Margate Location not found\n",
      "Scarborough Location not found\n",
      "Bournemouth Location not found\n",
      "Swansea Location not found\n",
      "Ramhead Location not found\n"
     ]
    }
   ],
   "source": [
    "num = 16\n",
    "print(f'RUN chapter {num}')\n",
    "data = get_gpe(chapters_v3[num-1])\n",
    "toJson(data, f'chapter_{num}_gpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "059ed4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN chapter 17\n",
      "Roundtown Location not found\n",
      "Zion Location not found\n",
      "Szombathely Location not found\n",
      "jehudi Location not found\n",
      "homijah Location not found\n",
      "Calcata Location not found\n",
      "Mizrach Location not found\n",
      "Southwark Location not found\n",
      "Flowerville Location not found\n",
      "covin Location not found\n",
      "venville Location not found\n",
      "Midlothian Location not found\n",
      "Ripon Location not found\n",
      "Szesfehervar Location not found\n",
      "Florence Location not found\n",
      "La Linea Location not found\n",
      "Thibet Location not found\n"
     ]
    }
   ],
   "source": [
    "num = 17\n",
    "print(f'RUN chapter {num}')\n",
    "data = get_gpe(chapters_v3[num-1])\n",
    "toJson(data, f'chapter_{num}_gpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2967e1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN chapter 18\n",
      "Bloemfontein Location not found\n",
      "Algeciras Location not found\n",
      "Lewers Location not found\n",
      "Helys Location not found\n",
      "Inces Location not found\n",
      "Trilby Location not found\n",
      "Lahore Location not found\n",
      "Abrines Location not found\n",
      "Liptons Location not found\n",
      "Trieste-Zurich Location not found\n",
      "Salt Lake City Location not found\n"
     ]
    }
   ],
   "source": [
    "num = 18\n",
    "print(f'RUN chapter {num}')\n",
    "data = get_gpe(chapters_v3[num-1])\n",
    "toJson(data, f'chapter_{num}_gpe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8917c57e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4d4aabe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_line(line: str, target_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Shorten the text line by trimming the line by \n",
    "    footstop (.), question mark (?) or exclamation mark (!),\n",
    "    getting only the text around the target string\n",
    "\n",
    "    Args:\n",
    "        line (str): The text line to be cleaned\n",
    "        target_str (str): The target string\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned text line\n",
    "    \"\"\"\n",
    "    # Find the target string in the line\n",
    "    target_index = line.find(target_str)\n",
    "    # Find the first footstop (.), question mark (?) or exclamation mark (!) after the target string\n",
    "    footstop_index = line.find(\".\", target_index)\n",
    "    question_index = line.find(\"?\", target_index)\n",
    "    exclamation_index = line.find(\"!\", target_index)\n",
    "    # Get the shortest index\n",
    "    if footstop_index == -1:\n",
    "        footstop_index = len(line)\n",
    "    if question_index == -1:\n",
    "        question_index = len(line)\n",
    "    if exclamation_index == -1:\n",
    "        exclamation_index = len(line)\n",
    "    # Get the shortest index\n",
    "    end_index = min(footstop_index, question_index, exclamation_index)\n",
    "    # Get the last footstop (.), question mark (?) or exclamation mark (!) before the target string\n",
    "    footstop_index = line.rfind(\".\", 0, target_index)\n",
    "    question_index = line.rfind(\"?\", 0, target_index)\n",
    "    exclamation_index = line.rfind(\"!\", 0, target_index)\n",
    "    # Get the longest index\n",
    "    start_index = max(footstop_index, question_index, exclamation_index)\n",
    "    # Return the cleaned text line\n",
    "    return line[start_index+1:end_index]\n",
    "    \n",
    "\n",
    "def filter_locations(latitude: float, longitude: float) -> bool:\n",
    "    \"\"\"\n",
    "    Filter the locations based on the latitude and longitude\n",
    "\n",
    "    Args:\n",
    "        latitude (float): The latitude of the location\n",
    "        longitude (float): The longitude of the location\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the location is within the range, False otherwise\n",
    "    \"\"\"\n",
    "    # Top left: 55.63588022503673, -10.958074311157244\n",
    "    # Bottom right: 51.10420379246764, -5.0255379638926465\n",
    "    if latitude < 51.10420379246764 or latitude > 55.63588022503673:\n",
    "        return False\n",
    "    if longitude < -10.958074311157244 or longitude > -5.0255379638926465:\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1e88e020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dottyville Location not found\n"
     ]
    }
   ],
   "source": [
    "chapter_list = []\n",
    "\n",
    "for i in range(0, 18):\n",
    "    chapter = get_gpe(chapters_v3[i])\n",
    "    for item in chapter:\n",
    "        # Skip if the nominatim is empty\n",
    "        if not chapter[item][\"nominatim\"]:\n",
    "            continue\n",
    "        if filter_locations(chapter[item][\"nominatim\"][0], chapter[item][\"nominatim\"][1]):\n",
    "            chapter_list.append({\n",
    "                \"chapter\": i+1,\n",
    "                \"gpe\": item,\n",
    "                \"nominatim\": chapter[item][\"nominatim\"],\n",
    "                \"count\": chapter[item][\"count\"],\n",
    "                \"part_of_text\": clean_text_line(chapter[item][\"part_of_text\"], item)\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "42edd02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "'Dublin'\n",
      "\n",
      "[53.3493795, -6.2605593]\n",
      "\n",
      "1\n",
      "\n",
      "('He mounted to the parapet again and gazed out over Dublin bay, his fair '\n",
      " 'oakpale hair stirring slightly')\n",
      "\n",
      "1\n",
      "\n",
      "'Kingstown'\n",
      "\n",
      "[53.2922794, -6.1360079]\n",
      "\n",
      "1\n",
      "\n",
      "(' Leaning on it he looked down on the water and on the mailboat clearing the '\n",
      " 'harbourmouth of Kingstown')\n",
      "\n",
      "1\n",
      "\n",
      "'Bray Head'\n",
      "\n",
      "[53.1904724, -6.0837452]\n",
      "\n",
      "1\n",
      "\n",
      "('They halted, looking towards the blunt cape of Bray Head that lay on the '\n",
      " 'water like the snout of a sleeping whale')\n",
      "\n",
      "1\n",
      "\n",
      "'Haines'\n",
      "\n",
      "[53.2894887, -6.1297938]\n",
      "\n",
      "4\n",
      "\n",
      "' Haines is apologising for waking us last night'\n",
      "\n",
      "1\n",
      "\n",
      "'Clongowes'\n",
      "\n",
      "[53.310525299999995, -6.686760774260252]\n",
      "\n",
      "1\n",
      "\n",
      "' So I carried the boat of incense then at Clongowes'\n",
      "\n",
      "1\n",
      "\n",
      "'Dundrum'\n",
      "\n",
      "[53.2891457, -6.2433756]\n",
      "\n",
      "1\n",
      "\n",
      "(' Five lines of text and ten pages of notes about the folk and the fishgods '\n",
      " 'of Dundrum')\n",
      "\n",
      "1\n",
      "\n",
      "'Ireland'\n",
      "\n",
      "[53.429500000000004, -8.1227484875]\n",
      "\n",
      "3\n",
      "\n",
      "('—He’s English, Buck Mulligan said, and he thinks we ought to speak Irish in '\n",
      " 'Ireland')\n",
      "\n",
      "1\n",
      "\n",
      "'Elsinore'\n",
      "\n",
      "[51.92629515, -8.180705743148366]\n",
      "\n",
      "1\n",
      "\n",
      "('—I mean to say, Haines explained to Stephen as they followed, this tower and '\n",
      " 'these cliffs here remind me somehow of Elsinore')\n",
      "\n",
      "1\n",
      "\n",
      "'Panama'\n",
      "\n",
      "[54.0044092, -6.4030016]\n",
      "\n",
      "1\n",
      "\n",
      "(' He moved a doll’s head to and fro, the brims of his Panama hat quivering, '\n",
      " 'and began to chant in a quiet happy foolish voice:')\n",
      "\n",
      "1\n",
      "\n",
      "'Bullock'\n",
      "\n",
      "[53.28040515, -6.11541293903381]\n",
      "\n",
      "1\n",
      "\n",
      "'—She’s making for Bullock harbour'\n",
      "\n",
      "1\n",
      "\n",
      "'Westmeath'\n",
      "\n",
      "[53.5577902, -7.3478558260097575]\n",
      "\n",
      "1\n",
      "\n",
      "'—Down in Westmeath'\n",
      "\n",
      "1\n",
      "\n",
      "'Carlisle'\n",
      "\n",
      "[53.2058818, -6.10268655231453]\n",
      "\n",
      "1\n",
      "\n",
      "' You know that red Carlisle girl, Lily'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in chapter_list:\n",
    "    for gpe in item:\n",
    "        pprint(item[gpe])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389bf46d",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
